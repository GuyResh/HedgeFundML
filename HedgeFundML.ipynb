{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bf2f320-541f-4990-bd0c-0824fabee9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hedge Fund ML (sandbox/playground/harness)\n",
    "#\n",
    "# (c)2022 Guy Resh\n",
    "#\n",
    "# - start fund on 1/1/2020 with $1B seed capital\n",
    "# - +$1B additional seed injections on 1/1/2021 & 1/1/2022\n",
    "# - tradable securities selected from Dow 30, Nasdaq 100 & S&P 500 (528 unique; less 8 partial)\n",
    "# - maintain portfolio with 50-100 \"best\" stocks\n",
    "# - maintain diversification with 5-10 different industry sectors\n",
    "# - generate Buy-and-Hold P/L % statistics for EOY 2020, 2021 & YTD 2022 for all 520 securities (long-only)\n",
    "# - generate \"opportunity\" (measured move statistics) P/L using fractal-based reversal pivot points for all 520 securities (long-only)\n",
    "# - maintain 1%-5% minimum monthly profit (stop at second consecutive losing month or if drawdown exceeds 10%)\n",
    "# - features/strategies based on CCI, DC, KR, LRBO, RSI, VWAP, Half/SuperTrend, Volume, Velocity/Momentum, etc.\n",
    "# - 0% commissions assumed (though can/should be accounted for at some point)\n",
    "# - whole share purchases-only (no fractional; round quantities down to nearest 100?)\n",
    "# - generate portfolio scenarios that rebalance daily, weekly, monthly and quarterly\n",
    "# - split-handling?\n",
    "# - dividend income inclusion?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1611fb31-abef-4dfd-8ff5-bff1df18f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from finvizfinance.quote import finvizfinance\n",
    "import pyiqfeed as iq\n",
    "from pyiqfeed.field_readers import read_posix_ts, date_us_to_datetime, datetime_to_yyyymmdd_hhmmss, us_since_midnight_to_time\n",
    "\n",
    "from math import floor\n",
    "from tqdm.notebook import tqdm\n",
    "from termcolor import colored as cl\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "\n",
    "pd.set_option( 'display.max_rows', None )\n",
    "pd.set_option( 'display.max_columns', None )\n",
    "pd.set_option( 'display.width', None )\n",
    "pd.set_option( 'display.max_colwidth', None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec8e8425-ed70-49d1-b065-24ffb57bdbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'linux':\n",
    "  home = '/mnt/f/db/IQFeed/'\n",
    "else:\n",
    "  home = 'F:/db/IQFeed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "685f8fe2-d00a-4e51-8984-ce234ac9bb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520 unique symbols\n"
     ]
    }
   ],
   "source": [
    "Dow30Syms = [\n",
    "\"AAPL\", \"AMGN\", \"AXP\", \"BA\", \"CAT\", \"CRM\", \"CSCO\", \"CVX\", \"DIS\", \"DOW\",\n",
    "\"GS\", \"HD\", \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"JPM\", \"KO\", \"MCD\", \"MMM\",\n",
    "\"MRK\", \"MSFT\", \"NKE\", \"PG\", \"TRV\", \"UNH\", \"V\", \"VZ\", \"WBA\", \"WMT\"\n",
    "]\n",
    "\n",
    "Nasdaq100Syms = [ # 102\n",
    "\"AAPL\", \"ABNB\", \"ADBE\", \"ADI\", \"ADP\", \"ADSK\", \"AEP\", \"ALGN\", \"AMAT\", \"AMD\",\n",
    "\"AMGN\", \"AMZN\", \"ANSS\", \"ASML\", \"ATVI\", \"AVGO\", \"AZN\", \"BIDU\", \"BIIB\", \"BKNG\",\n",
    "\"CDNS\", \"CEG\", \"CHTR\", \"CMCSA\", \"COST\", \"CPRT\", \"CRWD\", \"CSCO\", \"CSX\", \"CTAS\",\n",
    "\"CTSH\", \"DDOG\", \"DLTR\", \"DOCU\", \"DXCM\", \"EA\", \"EBAY\", \"EXC\", \"FAST\", \"FB\",\n",
    "\"FISV\", \"FTNT\", \"GILD\", \"GOOG\", \"GOOGL\", \"HON\", \"IDXX\", \"ILMN\", \"INTC\", \"INTU\",\n",
    "\"ISRG\", \"JD\", \"KDP\", \"KHC\", \"KLAC\", \"LCID\", \"LRCX\", \"LULU\", \"MAR\", \"MCHP\",\n",
    "\"MDLZ\", \"MELI\", \"MNST\", \"MRNA\", \"MRVL\", \"MSFT\", \"MTCH\", \"MU\", \"NFLX\", \"NTES\",\n",
    "\"NVDA\", \"NXPI\", \"ODFL\", \"OKTA\", \"ORLY\", \"PANW\", \"PAYX\", \"PCAR\", \"PDD\", \"PEP\",\n",
    "\"PYPL\", \"QCOM\", \"REGN\", \"ROST\", \"SBUX\", \"SGEN\", \"SIRI\", \"SNPS\", \"SPLK\", \"SWKS\",\n",
    "\"TEAM\", \"TMUS\", \"TSLA\", \"TXN\", \"VRSK\", \"VRSN\", \"VRTX\", \"WBA\", \"WDAY\", \"XEL\",\n",
    "\"ZM\", \"ZS\"\n",
    "]\n",
    "\n",
    "SP500Syms = [ # 504\n",
    "\"A\", \"AAL\", \"AAP\", \"AAPL\", \"ABBV\", \"ABC\", \"ABMD\", \"ABT\", \"ACN\", \"ADBE\",\n",
    "\"ADI\", \"ADM\", \"ADP\", \"ADSK\", \"AEE\", \"AEP\", \"AES\", \"AFL\", \"AIG\", \"AIZ\",\n",
    "\"AJG\", \"AKAM\", \"ALB\", \"ALGN\", \"ALK\", \"ALL\", \"ALLE\", \"AMAT\", \"AMCR\", \"AMD\",\n",
    "\"AME\", \"AMGN\", \"AMP\", \"AMT\", \"AMZN\", \"ANET\", \"ANSS\", \"ANTM\", \"AON\", \"AOS\",\n",
    "\"APA\", \"APD\", \"APH\", \"APTV\", \"ARE\", \"ATO\", \"ATVI\", \"AVB\", \"AVGO\", \"AVY\",\n",
    "\"AWK\", \"AXP\", \"AZO\", \"BA\", \"BAC\", \"BAX\", \"BBWI\", \"BBY\", \"BDX\", \"BEN\",\n",
    "\"BF.B\", \"BIIB\", \"BIO\", \"BK\", \"BKNG\", \"BKR\", \"BLK\", \"BLL\", \"BMY\", \"BR\",\n",
    "\"BRK.B\", \"BRO\", \"BSX\", \"BWA\", \"BXP\", \"C\", \"CAG\", \"CAH\", \"CARR\", \"CAT\",\n",
    "\"CB\", \"CBOE\", \"CBRE\", \"CCI\", \"CCL\", \"CDAY\", \"CDNS\", \"CDW\", \"CE\", \"CEG\",\n",
    "\"CERN\", \"CF\", \"CFG\", \"CHD\", \"CHRW\", \"CHTR\", \"CI\", \"CINF\", \"CL\", \"CLX\",\n",
    "\"CMA\", \"CMCSA\", \"CME\", \"CMG\", \"CMI\", \"CMS\", \"CNC\", \"CNP\", \"COF\", \"COO\",\n",
    "\"COP\", \"COST\", \"CPB\", \"CPRT\", \"CPT\", \"CRL\", \"CRM\", \"CSCO\", \"CSX\", \"CTAS\",\n",
    "\"CTLT\", \"CTRA\", \"CTSH\", \"CTVA\", \"CTXS\", \"CVS\", \"CVX\", \"CZR\", \"D\", \"DAL\",\n",
    "\"DD\", \"DE\", \"DFS\", \"DG\", \"DGX\", \"DHI\", \"DHR\", \"DIS\", \"DISH\", \"DLR\",\n",
    "\"DLTR\", \"DOV\", \"DOW\", \"DPZ\", \"DRE\", \"DRI\", \"DTE\", \"DUK\", \"DVA\", \"DVN\",\n",
    "\"DXC\", \"DXCM\", \"EA\", \"EBAY\", \"ECL\", \"ED\", \"EFX\", \"EIX\", \"EL\", \"EMN\",\n",
    "\"EMR\", \"ENPH\", \"EOG\", \"EPAM\", \"EQIX\", \"EQR\", \"ES\", \"ESS\", \"ETN\", \"ETR\",\n",
    "\"ETSY\", \"EVRG\", \"EW\", \"EXC\", \"EXPD\", \"EXPE\", \"EXR\", \"F\", \"FANG\", \"FAST\",\n",
    "\"FB\", \"FBHS\", \"FCX\", \"FDS\", \"FDX\", \"FE\", \"FFIV\", \"FIS\", \"FISV\", \"FITB\",\n",
    "\"FLT\", \"FMC\", \"FOX\", \"FOXA\", \"FRC\", \"FRT\", \"FTNT\", \"FTV\", \"GD\", \"GE\",\n",
    "\"GILD\", \"GIS\", \"GL\", \"GLW\", \"GM\", \"GNRC\", \"GOOG\", \"GOOGL\", \"GPC\", \"GPN\",\n",
    "\"GRMN\", \"GS\", \"GWW\", \"HAL\", \"HAS\", \"HBAN\", \"HCA\", \"HD\", \"HES\", \"HIG\",\n",
    "\"HII\", \"HLT\", \"HOLX\", \"HON\", \"HPE\", \"HPQ\", \"HRL\", \"HSIC\", \"HST\", \"HSY\",\n",
    "\"HUM\", \"HWM\", \"IBM\", \"ICE\", \"IDXX\", \"IEX\", \"IFF\", \"ILMN\", \"INCY\", \"INTC\",\n",
    "\"INTU\", \"IP\", \"IPG\", \"IPGP\", \"IQV\", \"IR\", \"IRM\", \"ISRG\", \"IT\", \"ITW\",\n",
    "\"IVZ\", \"J\", \"JBHT\", \"JCI\", \"JKHY\", \"JNJ\", \"JNPR\", \"JPM\", \"K\", \"KEY\",\n",
    "\"KEYS\", \"KHC\", \"KIM\", \"KLAC\", \"KMB\", \"KMI\", \"KMX\", \"KO\", \"KR\", \"L\",\n",
    "\"LDOS\", \"LEN\", \"LH\", \"LHX\", \"LIN\", \"LKQ\", \"LLY\", \"LMT\", \"LNC\", \"LNT\",\n",
    "\"LOW\", \"LRCX\", \"LUMN\", \"LUV\", \"LVS\", \"LW\", \"LYB\", \"LYV\", \"MA\", \"MAA\",\n",
    "\"MAR\", \"MAS\", \"MCD\", \"MCHP\", \"MCK\", \"MCO\", \"MDLZ\", \"MDT\", \"MET\", \"MGM\",\n",
    "\"MHK\", \"MKC\", \"MKTX\", \"MLM\", \"MMC\", \"MMM\", \"MNST\", \"MO\", \"MOH\", \"MOS\",\n",
    "\"MPC\", \"MPWR\", \"MRK\", \"MRNA\", \"MRO\", \"MS\", \"MSCI\", \"MSFT\", \"MSI\", \"MTB\",\n",
    "\"MTCH\", \"MTD\", \"MU\", \"NCLH\", \"NDAQ\", \"NDSN\", \"NEE\", \"NEM\", \"NFLX\", \"NI\",\n",
    "\"NKE\", \"NLOK\", \"NLSN\", \"NOC\", \"NOW\", \"NRG\", \"NSC\", \"NTAP\", \"NTRS\", \"NUE\",\n",
    "\"NVDA\", \"NVR\", \"NWL\", \"NWS\", \"NWSA\", \"NXPI\", \"O\", \"ODFL\", \"OGN\", \"OKE\",\n",
    "\"OMC\", \"ORCL\", \"ORLY\", \"OTIS\", \"OXY\", \"PARA\", \"PAYC\", \"PAYX\", \"PCAR\", \"PEAK\",\n",
    "\"PEG\", \"PENN\", \"PEP\", \"PFE\", \"PFG\", \"PG\", \"PGR\", \"PH\", \"PHM\", \"PKG\",\n",
    "\"PKI\", \"PLD\", \"PM\", \"PNC\", \"PNR\", \"PNW\", \"POOL\", \"PPG\", \"PPL\", \"PRU\",\n",
    "\"PSA\", \"PSX\", \"PTC\", \"PVH\", \"PWR\", \"PXD\", \"PYPL\", \"QCOM\", \"QRVO\", \"RCL\",\n",
    "\"RE\", \"REG\", \"REGN\", \"RF\", \"RHI\", \"RJF\", \"RL\", \"RMD\", \"ROK\", \"ROL\",\n",
    "\"ROP\", \"ROST\", \"RSG\", \"RTX\", \"SBAC\", \"SBNY\", \"SBUX\", \"SCHW\", \"SEDG\", \"SEE\",\n",
    "\"SHW\", \"SIVB\", \"SJM\", \"SLB\", \"SNA\", \"SNPS\", \"SO\", \"SPG\", \"SPGI\", \"SRE\",\n",
    "\"STE\", \"STT\", \"STX\", \"STZ\", \"SWK\", \"SWKS\", \"SYF\", \"SYK\", \"SYY\", \"T\",\n",
    "\"TAP\", \"TDG\", \"TDY\", \"TECH\", \"TEL\", \"TER\", \"TFC\", \"TFX\", \"TGT\", \"TJX\",\n",
    "\"TMO\", \"TMUS\", \"TPR\", \"TRMB\", \"TROW\", \"TRV\", \"TSCO\", \"TSLA\", \"TSN\", \"TT\",\n",
    "\"TTWO\", \"TWTR\", \"TXN\", \"TXT\", \"TYL\", \"UA\", \"UAA\", \"UAL\", \"UDR\", \"UHS\",\n",
    "\"ULTA\", \"UNH\", \"UNP\", \"UPS\", \"URI\", \"USB\", \"V\", \"VFC\", \"VLO\", \"VMC\",\n",
    "\"VNO\", \"VRSK\", \"VRSN\", \"VRTX\", \"VTR\", \"VTRS\", \"VZ\", \"WAB\", \"WAT\", \"WBA\",\n",
    "\"WBD\", \"WDC\", \"WEC\", \"WELL\", \"WFC\", \"WHR\", \"WM\", \"WMB\", \"WMT\", \"WRB\",\n",
    "\"WRK\", \"WST\", \"WTW\", \"WY\", \"WYNN\", \"XEL\", \"XOM\", \"XRAY\", \"XYL\", \"YUM\",\n",
    "\"ZBH\", \"ZBRA\", \"ZION\", \"ZTS\"\n",
    "]\n",
    "\n",
    "uniqueSymbols = np.sort( np.unique( np.array( Dow30Syms + Nasdaq100Syms + SP500Syms ))).tolist()\n",
    "\n",
    "#\n",
    "# Don't include these symbols that don't have a full complement of data (IPO'd after 1/1/2020?)\n",
    "#\n",
    "#ABNB.pkl: 2020-12-10 13:40:00\n",
    "#CARR.pkl: 2020-03-19 15:45:00\n",
    "#CEG.pkl: 2022-01-19 10:25:00\n",
    "#LCID.pkl: 2020-09-18 09:40:00\n",
    "#OGN.pkl: 2021-05-14 11:35:00\n",
    "#OTIS.pkl: 2020-03-19 11:40:00\n",
    "#VTRS.pkl: 2020-11-12 09:35:00\n",
    "#WBD.pkl: 2022-04-04 09:35:00\n",
    "partialSymbols = [\"ABNB\",\"CARR\",\"CEG\",\"LCID\",\"OGN\",\"OTIS\",\"VTRS\",\"WBD\"]\n",
    "for symbol in partialSymbols:\n",
    "  uniqueSymbols.remove( symbol ) \n",
    "\n",
    "print( len( uniqueSymbols ), 'unique symbols' ) # 528-8\n",
    "#print( list( uniqueSymbols ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef1fdd10-64c5-441f-a666-4e4177af4e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 520 ] fundamental data loaded...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Download/persist (some) fundamental data from finviz\n",
    "#\n",
    "fundamentals = {}\n",
    "fn_json = 'data/fundamentals.json'\n",
    "if not os.path.isfile( fn_json ):\n",
    "  for symbol in uniqueSymbols:\n",
    "    finvizSymbol = symbol.replace( '.', '-' )\n",
    "    try:\n",
    "      stock = finvizfinance( finvizSymbol )\n",
    "    except (RuntimeError, TypeError, NameError):\n",
    "      pass\n",
    "    finvizFundamentals = stock.ticker_fundament()\n",
    "    fundamentals[symbol] = {\n",
    "      'Company':   finvizFundamentals['Company'],\n",
    "      'Sector':    finvizFundamentals['Sector'],\n",
    "      'Industry':  finvizFundamentals['Industry'],\n",
    "      'MarketCap': finvizFundamentals['Market Cap']\n",
    "    }\n",
    "    #print( symbol, fundamentals[symbol] )\n",
    "\n",
    "  dfFundamentals = pd.DataFrame.from_dict( fundamentals, orient=\"index\" )\n",
    "  #print( dfFundamentals.info() )\n",
    "  #print( dfFundamentals )\n",
    "\n",
    "  jsonObj = json.loads( dfFundamentals.to_json( orient=\"index\" ))\n",
    "  jsonFundamentals = json.dumps( jsonObj, indent=2 )\n",
    "  print( jsonFundamentals )\n",
    "  with open( fn_json, \"w\" ) as f:\n",
    "    f.write( jsonFundamentals )\n",
    "\n",
    "dfFundamentals = pd.read_json( fn_json, orient=\"index\" )\n",
    "#print( dfFundamentals[0:10] )\n",
    "print( \"[\", len( dfFundamentals ), \"] fundamental data loaded...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "779f675f-059d-4fe5-8f35-530823a03e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Download 5 minute bars from IQFeed from bgn_prd to end_prd and return as a Pandas DataFrame\n",
    "#\n",
    "def get_historical_data( symbol, bgn_prd: datetime.datetime, end_prd: datetime.datetime ):\n",
    "\n",
    "  print( 'get_historical_data(', symbol, ',', datetime_to_yyyymmdd_hhmmss( bgn_prd ), ',', datetime_to_yyyymmdd_hhmmss( end_prd ), ')' )\n",
    "\n",
    "  histConn = iq.HistoryConn( name=\"pyiqfeed\" )\n",
    "  histConn.connect()\n",
    "  histListener = iq.VerboseIQFeedListener( 'History Tick Listener' )\n",
    "  histConn.add_listener( histListener )\n",
    "\n",
    "  #dt, tm = read_posix_ts( bp_str )\n",
    "  #bgn_prd = date_us_to_datetime( dt, tm )\n",
    "  #dt, tm = read_posix_ts( ep_str )\n",
    "  #end_prd = date_us_to_datetime( dt, tm )\n",
    "\n",
    "  # dtype([('date', '<M8[D]'), ('time', '<m8[us]'), ('open_p', '<f8'), ('high_p', '<f8'), ('low_p', '<f8'), ('close_p', '<f8'), ('tot_vlm', '<u8'), ('prd_vlm', '<u8'), ('num_trds', '<u8')])\n",
    "  ndarray = histConn.request_bars_in_period(\n",
    "    ticker = symbol,\n",
    "    interval_len = 300, # 5 min bars\n",
    "    interval_type = 's',\n",
    "    bgn_prd = bgn_prd,\n",
    "    end_prd = end_prd,\n",
    "    bgn_flt = datetime.time.fromisoformat( '09:30:00' ), # None,\n",
    "    end_flt = datetime.time.fromisoformat( '16:00:00' ), # None,\n",
    "    ascend = True,\n",
    "    max_bars = None,\n",
    "    label_at_beginning = False,\n",
    "    timeout = 30\n",
    "  )\n",
    "  df = pd.DataFrame( ndarray )\n",
    "  df['datetime'] = df['date'] + df['time']\n",
    "  df.drop('date', axis=1, inplace=True)\n",
    "  df.drop('time', axis=1, inplace=True)\n",
    "  df.drop('tot_vlm', axis=1, inplace=True)\n",
    "  df.drop('num_trds', axis=1, inplace=True)\n",
    "  df.rename( columns={'open_p': 'open', 'high_p': 'high', 'low_p': 'low', 'close_p': 'close', 'prd_vlm': 'volume'}, inplace=True)\n",
    "  df.set_index( 'datetime', inplace=True )\n",
    "  #print( df.info() )\n",
    "\n",
    "  histConn.remove_listener( histListener )\n",
    "  histConn.disconnect()\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30dac027-1f55-408c-82e8-3b77b9b74250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 520 ] 5-minute data loaded...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate/persist and load 5-minute OHLCV data from IQFeed for all 520 symbols\n",
    "#\n",
    "ohlcv = {}\n",
    "bgn_prd = datetime.datetime( year=2020, month=1, day=1, hour=0, minute=0, second=0 )\n",
    "end_prd = datetime.datetime.now()\n",
    "\n",
    "for i in tqdm( range( len( uniqueSymbols )), leave=False ):\n",
    "  \n",
    "  symbol = uniqueSymbols[i]\n",
    "  #print( 'symbol=[', symbol, ']' )\n",
    "\n",
    "  fn_pkl = 'data/5min/' + symbol + '.pkl'\n",
    "\n",
    "  if not os.path.isfile( fn_pkl ): # only download if we don't already have the data locally\n",
    "    iqData = get_historical_data( symbol, bgn_prd, end_prd )\n",
    "    #print( iqData[:5] )\n",
    "    startTime = datetime.datetime.now()\n",
    "    iqData.to_pickle( fn_pkl )\n",
    "    deltaTime = datetime.datetime.now() - startTime\n",
    "    #print( \"iqData to_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  startTime = datetime.datetime.now()\n",
    "  ohlcv[symbol] = pd.read_pickle( fn_pkl )\n",
    "  deltaTime = datetime.datetime.now() - startTime\n",
    "  #print( len( ohlcv[symbol] ), \"ohlcv read_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "print( \"[\", len( ohlcv ), \"] 5-minute data loaded...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39bb240d-7e67-4d10-b92e-7dddafa8844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 520 ] hourly data loaded...\n",
      "[ 520 ] daily data loaded...\n",
      "[ 520 ] weekly data loaded...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate and load hourly, daily and weekly data from 5 minute OHLCV data for all 520 symbols\n",
    "#\n",
    "ohlcvH = {}\n",
    "ohlcvD = {}\n",
    "ohlcvW = {}\n",
    "how = {\n",
    "  'open': 'first',\n",
    "  'high': 'max',\n",
    "  'low': 'min',\n",
    "  'close': 'last',\n",
    "  'volume': 'sum'\n",
    "}\n",
    "\n",
    "for i in tqdm( range( len( uniqueSymbols )), leave=False ):\n",
    "\n",
    "  symbol = uniqueSymbols[i]\n",
    "\n",
    "  fn_pkl = 'data/hourly/' + symbol + '.pkl'\n",
    "\n",
    "  if not os.path.isfile( fn_pkl ): # only download if we don't already have the data locally\n",
    "    df = ohlcv[symbol].resample( '1h', offset=0 ).apply( how ).dropna()\n",
    "    #print( ohlcv[symbol][:20] )\n",
    "    #print( df[:20] )\n",
    "    startTime = datetime.datetime.now()\n",
    "    df.to_pickle( fn_pkl )\n",
    "    deltaTime = datetime.datetime.now() - startTime\n",
    "    #print( \"hourly to_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  startTime = datetime.datetime.now()\n",
    "  ohlcvH[symbol] = pd.read_pickle( fn_pkl )\n",
    "  deltaTime = datetime.datetime.now() - startTime\n",
    "  #print( len( ohlcvH[symbol] ), \"hourly read_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  fn_pkl = 'data/daily/' + symbol + '.pkl'\n",
    "\n",
    "  if not os.path.isfile( fn_pkl ): # only download if we don't already have the data locally\n",
    "    df = ohlcv[symbol].resample( '1d', offset=0 ).apply( how ).dropna()\n",
    "    #print( ohlcv[symbol][:20] )\n",
    "    #print( df[:20] )\n",
    "    startTime = datetime.datetime.now()\n",
    "    df.to_pickle( fn_pkl )\n",
    "    deltaTime = datetime.datetime.now() - startTime\n",
    "    #print( \"hourly to_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  startTime = datetime.datetime.now()\n",
    "  ohlcvD[symbol] = pd.read_pickle( fn_pkl )\n",
    "  deltaTime = datetime.datetime.now() - startTime\n",
    "  #print( len( ohlcvH[symbol] ), \"hourly read_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  fn_pkl = 'data/weekly/' + symbol + '.pkl'\n",
    "\n",
    "  if not os.path.isfile( fn_pkl ): # only download if we don't already have the data locally\n",
    "    df = ohlcv[symbol].resample( '1w', offset=0 ).apply( how ).dropna()\n",
    "    #print( ohlcv[symbol][:20] )\n",
    "    #print( df[:20] )\n",
    "    startTime = datetime.datetime.now()\n",
    "    df.to_pickle( fn_pkl )\n",
    "    deltaTime = datetime.datetime.now() - startTime\n",
    "    #print( \"hourly to_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "  startTime = datetime.datetime.now()\n",
    "  ohlcvW[symbol] = pd.read_pickle( fn_pkl )\n",
    "  deltaTime = datetime.datetime.now() - startTime\n",
    "  #print( len( ohlcvH[symbol] ), \"hourly read_pickle(\" + fn_pkl + \") elapsed {:.3f}ms\".format( deltaTime.total_seconds() * 1000 )) # milliseconds\n",
    "\n",
    "print( \"[\", len( ohlcvH ), \"] hourly data loaded...\" )\n",
    "print( \"[\", len( ohlcvD ), \"] daily data loaded...\" )\n",
    "print( \"[\", len( ohlcvW ), \"] weekly data loaded...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f42f3ed2-c12d-4367-8207-740cb09f1767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 520 ] Fractal/Pivot generation elapsed 19.813s\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Generate fractal/pivot reversal points\n",
    "#\n",
    "TP = 50 # TODO: ATR-based?\n",
    "startTime = datetime.datetime.now()\n",
    "\n",
    "for i in tqdm( range( len( uniqueSymbols )), leave=False ):\n",
    "\n",
    "  symbol = uniqueSymbols[i]\n",
    "  #print( 'symbol=[', symbol, ']' )\n",
    "\n",
    "  df_tmp = ohlcv[symbol][['high', 'low', 'open']].copy()\n",
    "\n",
    "  df_tmp = df_tmp.assign(fh = np.where(\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(1)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(2)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(3)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(4)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(-1)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(-2)), # &\n",
    "    #(df_tmp['high'] > df_tmp['high'].shift(-3)),\n",
    "    1, 0\n",
    "  ))\n",
    "  df_tmp = df_tmp.assign(fl = np.where(\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(1)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(2)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(3)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(4)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(-1)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(-2)), # &\n",
    "    #(df_tmp['low'] < df_tmp['low'].shift(-3)),\n",
    "    1, 0\n",
    "  ))\n",
    "  df_tmp = df_tmp[['fh', 'fl']]\n",
    "  ohlcv[symbol].loc[:, 'fh42'] = df_tmp['fh']\n",
    "  ohlcv[symbol].loc[:, 'fl42'] = df_tmp['fl']\n",
    "  \n",
    "  #\n",
    "  # Determine if fractal/pivot reversal points were a \"verified\" win (within the next 3 bars)\n",
    "  #\n",
    "  df_tmp = ohlcv[symbol][['high', 'low', 'open']].copy()\n",
    "  #print( \"===[ df_tmp ]===\\n\", df_tmp.head(20), sep='')\n",
    "\n",
    "  df_tmp = df_tmp.assign(fh = np.where(\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(1)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(2)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(3)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(4)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(-1)) &\n",
    "    (df_tmp['high'] > df_tmp['high'].shift(-2)) &\n",
    "    (\n",
    "      (((df_tmp['open'].shift(-1) - df_tmp['low'].shift(-2)) / .01) >= TP) |\n",
    "      (((df_tmp['open'].shift(-1) - df_tmp['low'].shift(-3)) / .01) >= TP) |\n",
    "      (((df_tmp['open'].shift(-1) - df_tmp['low'].shift(-4)) / .01) >= TP) |\n",
    "      (((df_tmp['open'].shift(-1) - df_tmp['low'].shift(-5)) / .01) >= TP) |\n",
    "      (((df_tmp['open'].shift(-1) - df_tmp['low'].shift(-6)) / .01) >= TP)\n",
    "    ),\n",
    "    #(df_tmp['high'] > df_tmp['high'].shift(-3)),\n",
    "    1, 0\n",
    "  ))\n",
    "  df_tmp = df_tmp.assign(fl = np.where(\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(1)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(2)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(3)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(4)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(-1)) &\n",
    "    (df_tmp['low'] < df_tmp['low'].shift(-2)) &\n",
    "    (\n",
    "      (((df_tmp['high'].shift(-2) - df_tmp['open'].shift(-1)) / .01) >= TP) |\n",
    "      (((df_tmp['high'].shift(-3) - df_tmp['open'].shift(-1)) / .01) >= TP) |\n",
    "      (((df_tmp['high'].shift(-4) - df_tmp['open'].shift(-1)) / .01) >= TP) |\n",
    "      (((df_tmp['high'].shift(-5) - df_tmp['open'].shift(-1)) / .01) >= TP) |\n",
    "      (((df_tmp['high'].shift(-6) - df_tmp['open'].shift(-1)) / .01) >= TP)\n",
    "    ),\n",
    "    #(df_tmp['low'] < df_tmp['low'].shift(-3)),\n",
    "    1, 0\n",
    "  ))\n",
    "  df_tmp = df_tmp[['fh', 'fl']]\n",
    "  ohlcv[symbol].loc[:, 'fh42v'] = df_tmp['fh']\n",
    "  ohlcv[symbol].loc[:, 'fl42v'] = df_tmp['fl']\n",
    "  #print( df_tmp.head(20) )\n",
    "\n",
    "deltaTime = datetime.datetime.now() - startTime\n",
    "\n",
    "print( \"[\", len( ohlcv ), \"] Fractal/Pivot generation elapsed {:.3f}s\".format( deltaTime.total_seconds() )) # milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9405368-789d-450b-a2e6-c9a0c125ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fh42</th>\n",
       "      <th>fl42</th>\n",
       "      <th>fh42v</th>\n",
       "      <th>fl42v</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:35:00</th>\n",
       "      <td>296.2400</td>\n",
       "      <td>296.926</td>\n",
       "      <td>295.1900</td>\n",
       "      <td>296.87</td>\n",
       "      <td>1649209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:40:00</th>\n",
       "      <td>296.9300</td>\n",
       "      <td>297.950</td>\n",
       "      <td>296.9000</td>\n",
       "      <td>297.27</td>\n",
       "      <td>1071400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:45:00</th>\n",
       "      <td>297.2700</td>\n",
       "      <td>297.710</td>\n",
       "      <td>296.8700</td>\n",
       "      <td>297.12</td>\n",
       "      <td>674630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:50:00</th>\n",
       "      <td>297.1300</td>\n",
       "      <td>297.420</td>\n",
       "      <td>296.8000</td>\n",
       "      <td>296.83</td>\n",
       "      <td>536942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 09:55:00</th>\n",
       "      <td>296.8000</td>\n",
       "      <td>297.300</td>\n",
       "      <td>296.7000</td>\n",
       "      <td>297.28</td>\n",
       "      <td>434840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:00:00</th>\n",
       "      <td>297.3000</td>\n",
       "      <td>298.150</td>\n",
       "      <td>297.2500</td>\n",
       "      <td>297.97</td>\n",
       "      <td>720271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:05:00</th>\n",
       "      <td>297.9900</td>\n",
       "      <td>298.080</td>\n",
       "      <td>297.5100</td>\n",
       "      <td>297.80</td>\n",
       "      <td>524797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:10:00</th>\n",
       "      <td>297.8000</td>\n",
       "      <td>298.410</td>\n",
       "      <td>297.8000</td>\n",
       "      <td>298.26</td>\n",
       "      <td>580352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:15:00</th>\n",
       "      <td>298.2693</td>\n",
       "      <td>298.310</td>\n",
       "      <td>297.3101</td>\n",
       "      <td>297.39</td>\n",
       "      <td>556495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 10:20:00</th>\n",
       "      <td>297.3701</td>\n",
       "      <td>297.610</td>\n",
       "      <td>296.9300</td>\n",
       "      <td>297.22</td>\n",
       "      <td>527967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open     high       low   close   volume  fh42  fl42  \\\n",
       "datetime                                                                        \n",
       "2020-01-02 09:35:00  296.2400  296.926  295.1900  296.87  1649209     0     0   \n",
       "2020-01-02 09:40:00  296.9300  297.950  296.9000  297.27  1071400     0     0   \n",
       "2020-01-02 09:45:00  297.2700  297.710  296.8700  297.12   674630     0     0   \n",
       "2020-01-02 09:50:00  297.1300  297.420  296.8000  296.83   536942     0     0   \n",
       "2020-01-02 09:55:00  296.8000  297.300  296.7000  297.28   434840     0     0   \n",
       "2020-01-02 10:00:00  297.3000  298.150  297.2500  297.97   720271     0     0   \n",
       "2020-01-02 10:05:00  297.9900  298.080  297.5100  297.80   524797     0     0   \n",
       "2020-01-02 10:10:00  297.8000  298.410  297.8000  298.26   580352     1     0   \n",
       "2020-01-02 10:15:00  298.2693  298.310  297.3101  297.39   556495     0     0   \n",
       "2020-01-02 10:20:00  297.3701  297.610  296.9300  297.22   527967     0     0   \n",
       "\n",
       "                     fh42v  fl42v  \n",
       "datetime                           \n",
       "2020-01-02 09:35:00      0      0  \n",
       "2020-01-02 09:40:00      0      0  \n",
       "2020-01-02 09:45:00      0      0  \n",
       "2020-01-02 09:50:00      0      0  \n",
       "2020-01-02 09:55:00      0      0  \n",
       "2020-01-02 10:00:00      0      0  \n",
       "2020-01-02 10:05:00      0      0  \n",
       "2020-01-02 10:10:00      1      0  \n",
       "2020-01-02 10:15:00      0      0  \n",
       "2020-01-02 10:20:00      0      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlcv['AAPL'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7913844-5895-4747-a715-7647b3d1d51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seedCapital=[ $1,000,000,000.00 ] investmentCapitalPerSymbol=[ $1,923,076.92 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "seedCapital = 1000000000\n",
    "investmentCapitalPerSymbol = seedCapital / len( uniqueSymbols )\n",
    "print( 'seedCapital=[ ${:,.2f}'.format( seedCapital ), '] investmentCapitalPerSymbol=[ ${:,.2f}'.format( investmentCapitalPerSymbol ), ']' )\n",
    "\n",
    "dictPortfolio = {}\n",
    "for i in tqdm( range( len( uniqueSymbols )), leave=False ):\n",
    "\n",
    "  symbol = uniqueSymbols[i]\n",
    "\n",
    "  open2020   = ohlcv[symbol].open['2020-01-02 09:35:00']\n",
    "  close2020  = ohlcv[symbol].close['2020-12-31 16:00:00']\n",
    "  pctChg2020 = (close2020 - open2020) / open2020\n",
    "  invest2020 = math.floor( investmentCapitalPerSymbol / open2020 ) * open2020\n",
    "\n",
    "  open2021   = ohlcv[symbol].open['2021-01-04 09:35:00']\n",
    "  close2021  = ohlcv[symbol].close['2021-12-31 16:00:00']\n",
    "  pctChg2021 = (close2021 - open2021) / open2021\n",
    "  invest2021 = math.floor( investmentCapitalPerSymbol / open2021 ) * open2021\n",
    "\n",
    "  open2022   = ohlcv[symbol].open['2022-01-03 09:35:00']\n",
    "  close2022  = ohlcv[symbol].close['2021-04-14 16:00:00']\n",
    "  pctChg2022 = (close2022 - open2022) / open2022\n",
    "  invest2022 = math.floor( investmentCapitalPerSymbol / open2022 ) * open2022\n",
    "\n",
    "  dictPortfolio[symbol] = [\n",
    "    open2020, close2020, pctChg2020 * 100.0, invest2020, invest2020 * pctChg2020,\n",
    "    open2021, close2021, pctChg2021 * 100.0, invest2021, invest2021 * pctChg2021,\n",
    "    open2022, close2022, pctChg2022 * 100.0, invest2022, invest2022 * pctChg2022\n",
    "  ]\n",
    "print( end=\"\\r\" )\n",
    "#print( dictPortfolio )\n",
    "\n",
    "dfPortfolio = pd.DataFrame.from_dict(\n",
    "  dictPortfolio, orient='index',\n",
    "  columns=[\n",
    "    'open2020','close2020','pctChg2020','invest2020','PnL2020',\n",
    "    'open2021','close2021','pctChg2021','invest2021','PnL2021',\n",
    "    'open2022','close2022','pctChg2022','invest2022','PnL2022'\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80172c6c-c85e-4105-9602-9c12d5820dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol  open2020  close2020  pctChg2020\n",
      "0    ENPH     26.37     175.47      565.42\n",
      "1    MRNA     19.57     104.47      433.83\n",
      "2      ZM     68.80     337.16      390.06\n",
      "3     PDD     38.50     177.67      361.48\n",
      "4      ZS     46.87     199.71      326.09\n",
      "5    CRWD     50.03     211.82      323.39\n",
      "6    ETSY     44.71     177.84      297.76\n",
      "7    PENN     25.97      86.38      232.61\n",
      "8    SEDG     97.00     319.12      228.99\n",
      "9    DOCU     74.31     222.39      199.27\n",
      "10   MELI    576.94    1674.80      190.29\n",
      "11   DDOG     38.22      98.42      157.51\n",
      "12     JD     35.96      87.85      144.30\n",
      "13   GNRC    101.38     227.42      124.32\n",
      "14   NVDA    238.75     522.12      118.69\n",
      "15   OKTA    116.75     254.27      117.79\n",
      "16   PYPL    109.47     234.31      114.04\n",
      "17   BBWI     18.25      37.18      103.73\n",
      "18   MPWR    180.12     366.23      103.33\n",
      "19    ALB     73.50     147.51      100.69\n",
      "20    AMD     46.86      91.72       95.73\n",
      "21    FCX     13.35      26.01       94.83\n",
      "22   CDNS     70.18     136.32       94.24\n",
      "23    NOW    284.96     550.42       93.16\n",
      "24   TEAM    121.15     233.87       93.04\n",
      "25   IDXX    261.53     499.98       91.18\n",
      "26   ALGN    281.20     534.55       90.10\n",
      "27    WST    150.25     283.37       88.60\n",
      "28   ABMD    172.51     324.30       87.99\n",
      "29   SNPS    140.31     259.24       84.76\n",
      "30   CTLT     56.54     103.97       83.89\n",
      "31   MTCH     82.77     151.19       82.66\n",
      "32   MRVL     27.00      47.54       76.07\n",
      "33   POOL    212.24     372.76       75.63\n",
      "34    PWR     41.07      72.03       75.38\n",
      "35    TER     68.84     119.89       74.16\n",
      "36   AMZN   1875.00    3256.41       73.68\n",
      "37   MSCI    260.09     446.36       71.62\n",
      "38   QCOM     89.05     152.24       70.96\n",
      "39   TMUS     78.88     134.84       70.94\n",
      "40    FDX    152.42     259.61       70.33\n",
      "41   PAYC    266.92     452.21       69.42\n",
      "42   DXCM    218.56     369.79       69.19\n",
      "43   TTWO    123.53     207.92       68.32\n",
      "44   TWTR     32.31      54.14       67.56\n",
      "45   EPAM    214.12     358.04       67.21\n",
      "46   BIDU    129.49     216.24       66.99\n",
      "47   TSLA    424.50     705.21       66.13\n",
      "48   NFLX    326.10     540.71       65.81\n",
      "49   ADSK    184.25     305.38       65.74        open2021  close2021  pctChg2021\n",
      "GE        10.89      94.47      767.49\n",
      "DVN       16.00      44.04      175.25\n",
      "MRO        6.78      16.43      142.33\n",
      "FTNT     149.57     359.40      140.29\n",
      "SBNY     136.59     323.67      136.96\n",
      "MRNA     107.23     254.05      136.92\n",
      "F          8.81      20.77      135.75\n",
      "FANG      49.01     107.82      120.00\n",
      "NUE       54.18     114.14      110.67\n",
      "IT       159.89     334.58      109.26\n",
      "EXR      115.73     226.81       95.98\n",
      "SPG       85.66     159.78       86.53\n",
      "EPAM     359.01     669.07       86.37\n",
      "APA       14.56      26.89       84.68\n",
      "ODFL     195.01     358.25       83.71\n",
      "BBWI      38.05      69.80       83.44\n",
      "MRVL      47.75      87.57       83.39\n",
      "CF        39.00      70.77       81.46\n",
      "STX       62.29     112.98       81.38\n",
      "MAA      126.69     229.52       81.17\n",
      "DDOG      98.69     178.12       80.48\n",
      "AMAT      87.22     157.31       80.36\n",
      "CPT       99.78     178.74       79.13\n",
      "RHI       62.51     111.47       78.32\n",
      "COP       40.50      72.20       78.27\n",
      "AZO     1183.56    2096.12       77.10\n",
      "SIVB     385.66     678.94       76.05\n",
      "EOG       50.76      88.84       75.02\n",
      "JCI       46.61      81.31       74.45\n",
      "IRM       30.00      52.32       74.40\n",
      "CBRE      62.74     108.47       72.89\n",
      "TSCO     140.72     238.66       69.60\n",
      "INTU     379.32     643.19       69.56\n",
      "LKQ       35.44      60.02       69.36\n",
      "PLD       99.55     168.39       69.15\n",
      "MOS       23.35      39.30       68.31\n",
      "WST      283.43     468.85       65.42\n",
      "GOOG    1757.54    2893.58       64.64\n",
      "REG       45.77      75.35       64.63\n",
      "GOOGL   1760.00    2897.04       64.60\n",
      "KIM       15.02      24.66       64.18\n",
      "KLAC     261.99     430.11       64.17\n",
      "DRE       40.04      65.66       63.99\n",
      "TECH     316.66     517.86       63.54\n",
      "LLY      169.02     276.11       63.36\n",
      "OXY       17.75      28.98       63.27\n",
      "LYV       73.42     119.74       63.09\n",
      "PSA      230.32     374.64       62.66\n",
      "TEAM     234.50     381.35       62.62\n",
      "PWR       70.80     114.69       61.99\n"
     ]
    }
   ],
   "source": [
    "dfPortfolio.sort_values( by=['pctChg2020'], ascending=False, inplace=True)\n",
    "df2020Top50 = dfPortfolio[['open2020','close2020','pctChg2020']][0:50]\n",
    "\n",
    "df2020Top50.reset_index(inplace=True)\n",
    "df2020Top50 = df2020Top50.rename( columns = {'index':'symbol'})\n",
    "\n",
    "df2020Top50\n",
    "\n",
    "dfPortfolio.sort_values( by=['pctChg2021'], ascending=False, inplace=True)\n",
    "df2021Top50 = dfPortfolio[['open2021','close2021','pctChg2021']][0:50]\n",
    "\n",
    "dfPortfolio.sort_values( by=['pctChg2022'], ascending=False, inplace=True)\n",
    "df2022Top50 = dfPortfolio[['open2022','close2022','pctChg2022']][0:50]\n",
    "\n",
    "with pd.option_context( 'display.width', 1000, 'display.precision', 2 ):\n",
    "  print( df2020Top50, df2021Top50 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e2754-7d69-442c-9dee-e49bb6476e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context( 'display.width', 1000, 'display.precision', 2 ):\n",
    "#  print( dfPortfolio )\n",
    "\n",
    "BnHPnL2020All = dfPortfolio['PnL2020'].sum()\n",
    "BnHPnL2021All = dfPortfolio['PnL2021'].sum()\n",
    "BnHPnL2022All = dfPortfolio['PnL2022'].sum()\n",
    "\n",
    "print( \"\\n2020 B&H PnL (All)=[ ${:,.2f}\".format( BnHPnL2020All ), \"({:.1f}%) ] \".format( (BnHPnL2020All / seedCapital) * 100.0 ))\n",
    "print( \"2021 B&H PnL (All)=[ ${:,.2f}\".format( BnHPnL2021All ), \"({:.1f}%) ] \".format( (BnHPnL2021All / seedCapital) * 100.0 ))\n",
    "print( \"YTD 2022 B&H PnL (All)=[ ${:,.2f}\".format( BnHPnL2022All ), \"({:.1f}%) ] \".format( (BnHPnL2022All / seedCapital) * 100.0 ))\n",
    "\n",
    "BnHPnL2020WinnersOnly = dfPortfolio.query(\"pctChg2020 > 0.0\")['PnL2020'].sum()\n",
    "BnHPnL2021WinnersOnly = dfPortfolio.query(\"pctChg2021 > 0.0\")['PnL2021'].sum()\n",
    "BnHPnL2022WinnersOnly = dfPortfolio.query(\"pctChg2022 > 0.0\")['PnL2022'].sum()\n",
    "\n",
    "numBnHPnL2020WinnersOnly = dfPortfolio.query(\"pctChg2020 > 0.0\")['PnL2020'].count()\n",
    "numBnHPnL2021WinnersOnly = dfPortfolio.query(\"pctChg2021 > 0.0\")['PnL2021'].count()\n",
    "numBnHPnL2022WinnersOnly = dfPortfolio.query(\"pctChg2022 > 0.0\")['PnL2022'].count()\n",
    "\n",
    "print( \"\\n2020 B&H PnL (Winners-only)=[ ${:,.2f}\".format( BnHPnL2020WinnersOnly ), \"({:.1f}%;\".format( (BnHPnL2020WinnersOnly / seedCapital) * 100.0 ), numBnHPnL2020WinnersOnly, 'of', len( uniqueSymbols ), ')]' )\n",
    "print( \"2021 B&H PnL (Winners-only)=[ ${:,.2f}\".format( BnHPnL2021WinnersOnly ), \"({:.1f}%;\".format( (BnHPnL2021WinnersOnly / seedCapital) * 100.0 ), numBnHPnL2021WinnersOnly, 'of', len( uniqueSymbols ), ')]' )\n",
    "print( \"YTD 2022 B&H PnL (Winners-only)=[ ${:,.2f}\".format( BnHPnL2022WinnersOnly ), \"({:.1f}%;\".format( (BnHPnL2022WinnersOnly / seedCapital) * 100.0 ), numBnHPnL2022WinnersOnly, 'of', len( uniqueSymbols ), ')]' )\n",
    "\n",
    "#ohlcv[] for symbol in uniqueSymbols\n",
    "sys.exit( 0 )\n",
    "\n",
    "# ROC CALCULATION\n",
    "\n",
    "def get_roc(close, n):\n",
    "  difference = close.diff(n)\n",
    "  nprev_values = close.shift(n)\n",
    "  roc = (difference / nprev_values) * 100\n",
    "  return roc\n",
    "\n",
    "# KST CALCULATION\n",
    "\n",
    "def get_kst(close, sma1, sma2, sma3, sma4, roc1, roc2, roc3, roc4, signal):\n",
    "  rcma1 = get_roc(close, roc1).rolling(sma1).mean()\n",
    "  rcma2 = get_roc(close, roc2).rolling(sma2).mean()\n",
    "  rcma3 = get_roc(close, roc3).rolling(sma3).mean()\n",
    "  rcma4 = get_roc(close, roc4).rolling(sma4).mean()\n",
    "  kst = (rcma1 * 1) + (rcma2 * 2) + (rcma3 * 3) + (rcma4 * 4)\n",
    "  signal = kst.rolling(signal).mean()\n",
    "  return kst, signal\n",
    "\n",
    "tsla['kst'], tsla['signal_line'] = get_kst(tsla['close'], 10, 10, 10, 15, 10, 15, 20, 30, 9)\n",
    "tsla = tsla[tsla.index >= '2022-01-01']\n",
    "print(tsla.tail())\n",
    "\n",
    "# KST INDICATOR PLOT\n",
    "\n",
    "ax1 = plt.subplot2grid((11,1), (0,0), rowspan = 5, colspan = 1)\n",
    "ax2 = plt.subplot2grid((11,1), (6,0), rowspan = 5, colspan = 1)\n",
    "ax1.plot(tsla['close'], linewidth = 2.5)\n",
    "ax1.set_title('TSLA CLOSING PRICES')\n",
    "ax2.plot(tsla['kst'], linewidth = 2, label = 'KST', color = 'orange')\n",
    "ax2.plot(tsla['signal_line'], linewidth = 2, label = 'SIGNAL', color = 'mediumorchid')\n",
    "ax2.legend()\n",
    "ax2.set_title('TSLA KST')\n",
    "plt.show()\n",
    "\n",
    "# KST CROSSOVER TRADING STRATEGY\n",
    "\n",
    "def implement_kst_strategy(prices, kst_line, signal_line):\n",
    "  buy_price = []\n",
    "  sell_price = []\n",
    "  kst_signal = []\n",
    "  signal = 0\n",
    "    \n",
    "  for i in range(len(kst_line)):\n",
    "        \n",
    "    if kst_line[i-1] < signal_line[i-1] and kst_line[i] > signal_line[i]:\n",
    "        if signal != 1:\n",
    "          buy_price.append(prices[i])\n",
    "          sell_price.append(np.nan)\n",
    "          signal = 1\n",
    "          kst_signal.append(signal)\n",
    "        else:\n",
    "          buy_price.append(np.nan)\n",
    "          sell_price.append(np.nan)\n",
    "          kst_signal.append(0)\n",
    "                \n",
    "    elif kst_line[i-1] > signal_line[i-1] and kst_line[i] < signal_line[i]:\n",
    "      if signal != -1:\n",
    "        buy_price.append(np.nan)\n",
    "        sell_price.append(prices[i])\n",
    "        signal = -1\n",
    "        kst_signal.append(signal)\n",
    "      else:\n",
    "        buy_price.append(np.nan)\n",
    "        sell_price.append(np.nan)\n",
    "        kst_signal.append(0)\n",
    "                \n",
    "    else:\n",
    "      buy_price.append(np.nan)\n",
    "      sell_price.append(np.nan)\n",
    "      kst_signal.append(0)\n",
    "            \n",
    "  return buy_price, sell_price, kst_signal\n",
    "\n",
    "buy_price, sell_price, kst_signal = implement_kst_strategy(tsla['close'], tsla['kst'], tsla['signal_line'])\n",
    "\n",
    "# TRADING SIGNALS PLOT\n",
    "\n",
    "ax1 = plt.subplot2grid((11,1), (0,0), rowspan = 5, colspan = 1)\n",
    "ax2 = plt.subplot2grid((11,1), (6,0), rowspan = 5, colspan = 1)\n",
    "ax1.plot(tsla['close'], linewidth = 2, label = 'TSLA')\n",
    "ax1.plot(tsla.index, buy_price, marker = '^', markersize = 12, linewidth = 0, color = 'green', label = 'BUY SIGNAL')\n",
    "ax1.plot(tsla.index, sell_price, marker = 'v', markersize = 12, linewidth = 0, color = 'r', label = 'SELL SIGNAL')\n",
    "ax1.legend()\n",
    "ax1.set_title('TSLA KST TRADING SIGNALS')\n",
    "ax2.plot(tsla['kst'], linewidth = 2, label = 'KST', color = 'orange')\n",
    "ax2.plot(tsla['signal_line'], linewidth = 2, label = 'SIGNAL', color = 'mediumorchid')\n",
    "ax2.legend()\n",
    "ax2.set_title('TSLA KST')\n",
    "plt.show()\n",
    "\n",
    "# STOCK POSITION\n",
    "\n",
    "position = []\n",
    "for i in range(len(kst_signal)):\n",
    "  if kst_signal[i] > 1:\n",
    "    position.append(0)\n",
    "  else:\n",
    "    position.append(1)\n",
    "        \n",
    "for i in range(len(tsla['close'])):\n",
    "  if kst_signal[i] == 1:\n",
    "    position[i] = 1\n",
    "  elif kst_signal[i] == -1:\n",
    "    position[i] = 0\n",
    "  else:\n",
    "    position[i] = position[i-1]\n",
    "        \n",
    "close_price = tsla['close']\n",
    "kst = tsla['kst']\n",
    "signal_line = tsla['signal_line']\n",
    "kst_signal = pd.DataFrame(kst_signal).rename(columns = {0:'kst_signal'}).set_index(tsla.index)\n",
    "position = pd.DataFrame(position).rename(columns = {0:'kst_position'}).set_index(tsla.index)\n",
    "\n",
    "frames = [close_price, kst, signal_line, kst_signal, position]\n",
    "strategy = pd.concat(frames, join = 'inner', axis = 1)\n",
    "\n",
    "print( strategy )\n",
    "print( strategy[35:40] )\n",
    "\n",
    "# BACKTESTING\n",
    "\n",
    "tsla_ret = pd.DataFrame(np.diff(tsla['close'])).rename(columns = {0:'returns'})\n",
    "kst_strategy_ret = []\n",
    "\n",
    "for i in range(len(tsla_ret)):\n",
    "  returns = tsla_ret['returns'][i]*strategy['kst_position'][i]\n",
    "  kst_strategy_ret.append(returns)\n",
    "    \n",
    "kst_strategy_ret_df = pd.DataFrame(kst_strategy_ret).rename(columns = {0:'kst_returns'})\n",
    "investment_value = 100000\n",
    "number_of_stocks = floor(investment_value/tsla['close'][0])\n",
    "kst_investment_ret = []\n",
    "\n",
    "for i in range(len(kst_strategy_ret_df['kst_returns'])):\n",
    "  returns = number_of_stocks*kst_strategy_ret_df['kst_returns'][i]\n",
    "  kst_investment_ret.append(returns)\n",
    "\n",
    "kst_investment_ret_df = pd.DataFrame(kst_investment_ret).rename(columns = {0:'investment_returns'})\n",
    "total_investment_ret = round(sum(kst_investment_ret_df['investment_returns']), 2)\n",
    "profit_percentage = floor((total_investment_ret/investment_value)*100)\n",
    "\n",
    "#print(cl('Profit gained from the KST strategy by investing $100k in TSLA : {}'.format(total_investment_ret), attrs = ['bold']))\n",
    "#print(cl('Profit percentage of the KST strategy : {}%'.format(profit_percentage), attrs = ['bold']))\n",
    "\n",
    "print( 'Profit gained from the KST strategy by investing $100k in TSLA : {}'.format( total_investment_ret ))\n",
    "print( 'Profit percentage of the KST strategy : {}%'.format( profit_percentage ))\n",
    "\n",
    "# SPY ETF COMPARISON\n",
    "\n",
    "def get_benchmark(start_date, investment_value):\n",
    "  spy = get_historical_data( 'SPY', bgn_prd, end_prd )['close']\n",
    "  benchmark = pd.DataFrame(np.diff(spy)).rename(columns = {0:'benchmark_returns'})\n",
    "    \n",
    "  investment_value = investment_value\n",
    "  number_of_stocks = floor(investment_value/spy[-1])\n",
    "  benchmark_investment_ret = []\n",
    "    \n",
    "  for i in range(len(benchmark['benchmark_returns'])):\n",
    "    returns = number_of_stocks*benchmark['benchmark_returns'][i]\n",
    "    benchmark_investment_ret.append(returns)\n",
    "\n",
    "  benchmark_investment_ret_df = pd.DataFrame(benchmark_investment_ret).rename(columns = {0:'investment_returns'})\n",
    "  return benchmark_investment_ret_df\n",
    "\n",
    "benchmark = get_benchmark('2022-01-01', 100000)\n",
    "\n",
    "investment_value = 100000\n",
    "total_benchmark_investment_ret = round(sum(benchmark['investment_returns']), 2)\n",
    "benchmark_profit_percentage = floor((total_benchmark_investment_ret/investment_value)*100)\n",
    "\n",
    "#print(cl('Benchmark profit by investing $100k : {}'.format(total_benchmark_investment_ret), attrs = ['bold']))\n",
    "#print(cl('Benchmark Profit percentage : {}%'.format(benchmark_profit_percentage), attrs = ['bold']))\n",
    "#print(cl('KST Strategy profit is {}% higher than the Benchmark Profit'.format(profit_percentage - benchmark_profit_percentage), attrs = ['bold']))\n",
    "\n",
    "print( 'Benchmark profit by investing $100k : {}'.format( total_benchmark_investment_ret ))\n",
    "print( 'Benchmark Profit percentage : {}%'.format( benchmark_profit_percentage ))\n",
    "print( 'KST Strategy profit is {}% higher than the Benchmark Profit'.format( profit_percentage - benchmark_profit_percentage ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
